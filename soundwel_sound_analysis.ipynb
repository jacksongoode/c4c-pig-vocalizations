{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "t0DwjEZeCJSD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from collections import Counter, defaultdict\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tm96VvPLn32",
        "outputId": "339fa68d-c5d4-49f5-cdc9-e7b64d553bf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Training hyperparameters (matching MATLAB NN_function.m)\n",
        "MAX_EPOCHS = 20\n",
        "INITIAL_LEARNING_RATE = 0.001\n",
        "MOMENTUM = 0.9\n",
        "LEARN_RATE_DROP_PERIOD = 5\n",
        "LEARN_RATE_DROP_FACTOR = 10 ** (-0.5)\n",
        "\n",
        "# Set a default image size for ResNet50\n",
        "IMAGE_SIZE = (224, 224)\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    \"\"\"PyTorch Dataset for loading images from file paths.\"\"\"\n",
        "\n",
        "    def __init__(self, file_paths, labels=None):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transforms.Compose(\n",
        "            [transforms.Resize(IMAGE_SIZE), transforms.ToTensor()]\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.file_paths[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        image = self.transform(image)\n",
        "\n",
        "        if self.labels is not None:\n",
        "            label = self.labels[idx]\n",
        "            return image, label\n",
        "        else:\n",
        "            return image\n",
        "\n",
        "\n",
        "def balance_dataset(file_paths, labels):\n",
        "    \"\"\"Balance dataset by downsampling to the minimum class count.\"\"\"\n",
        "    # Count each label\n",
        "    counter = Counter(labels)\n",
        "    min_count = min(counter.values())\n",
        "    balanced_files = []\n",
        "    balanced_labels = []\n",
        "    label_to_files = {}\n",
        "    for fp, lab in zip(file_paths, labels):\n",
        "        label_to_files.setdefault(lab, []).append(fp)\n",
        "    for lab, fps in label_to_files.items():\n",
        "        fps = np.array(fps)\n",
        "        # Randomly choose min_count files for this label\n",
        "        indices = np.random.choice(len(fps), min_count, replace=False)\n",
        "        balanced_files.extend(fps[indices].tolist())\n",
        "        balanced_labels.extend([lab] * min_count)\n",
        "    return balanced_files, balanced_labels\n",
        "\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping to stop training when validation loss doesn't improve.\"\"\"\n",
        "\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path=\"checkpoint.pt\"):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        if self.verbose:\n",
        "            print(\n",
        "                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...\"\n",
        "            )\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "def nn_function(\n",
        "    file_paths,\n",
        "    labels,\n",
        "    equalize_labels,\n",
        "    minibatch_size,\n",
        "    validation_patience,\n",
        "    checkpoint_path,\n",
        "    use_amp=False,\n",
        "    skip_training=False\n",
        "):\n",
        "    \"\"\"\n",
        "    Equivalent to MATLAB NN_function.m using PyTorch\n",
        "    Parameters:\n",
        "        file_paths (list): List of image file paths (strings).\n",
        "        labels (list): List of labels corresponding to each image.\n",
        "        equalize_labels (bool): Whether to equalize label counts in the dataset.\n",
        "        minibatch_size (int): Batch size for training.\n",
        "        validation_patience (int): Patience for early stopping.\n",
        "        checkpoint_path (str): Directory to save model checkpoints.\n",
        "        use_amp (bool): Whether to use mixed precision training.\n",
        "\n",
        "    Returns:\n",
        "        model: The trained PyTorch model.\n",
        "        train_loader: Training data loader.\n",
        "        val_loader: Validation data loader.\n",
        "        val_labels: List of validation labels.\n",
        "        val_label_counts: Dictionary with counts per label in the validation set.\n",
        "        val_loader: Augmented validation data loader (same as val_loader here).\n",
        "    \"\"\"\n",
        "    # If equalizing labels, balance the dataset\n",
        "    if equalize_labels:\n",
        "        file_paths, labels = balance_dataset(file_paths, labels)\n",
        "\n",
        "    # Split dataset into training (70%) and validation (30%) sets\n",
        "    train_files, val_files, train_labels, val_labels = train_test_split(\n",
        "        file_paths, labels, test_size=0.3, stratify=labels, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create PyTorch datasets and data loaders\n",
        "    train_dataset = ImageDataset(train_files, train_labels)\n",
        "    val_dataset = ImageDataset(val_files, val_labels)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=minibatch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=minibatch_size, shuffle=False)\n",
        "\n",
        "    # Determine number of classes\n",
        "    classes = np.unique(labels)\n",
        "    num_classes = len(classes)\n",
        "\n",
        "    # Load the pretrained ResNet50 model\n",
        "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    # Freeze the base model\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Replace the final classification layer\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "    # Move model to device (CPU/GPU/MPS)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Set up loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=INITIAL_LEARNING_RATE, momentum=MOMENTUM)\n",
        "\n",
        "    # Set up learning rate scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=LEARN_RATE_DROP_PERIOD, gamma=LEARN_RATE_DROP_FACTOR)\n",
        "\n",
        "    # Prepare checkpoint directory\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        os.makedirs(checkpoint_path)\n",
        "\n",
        "    # Setup early stopping\n",
        "    early_stopping = EarlyStopping(\n",
        "        patience=validation_patience,\n",
        "        verbose=True,\n",
        "        path=os.path.join(checkpoint_path, \"model_checkpoint_best.pt\"),\n",
        "    )\n",
        "\n",
        "    # Initialize GradScaler for mixed precision\n",
        "    scaler = torch.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "    # Training loop\n",
        "    n_epochs = MAX_EPOCHS\n",
        "    # Determine validation frequency: floor(number of training iterations per epoch)\n",
        "    val_frequency = max(1, len(train_dataset) // minibatch_size)\n",
        "    global_iteration = 0\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        iteration = 0\n",
        "\n",
        "        for inputs, target_labels in train_loader:\n",
        "            iteration += 1\n",
        "            global_iteration += 1\n",
        "            inputs, target_labels = inputs.to(device), target_labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Use mixed precision if enabled\n",
        "            with torch.amp.autocast(device_type=\"cuda\", enabled=use_amp):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, target_labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target_labels.size(0)\n",
        "            correct += (predicted == target_labels).sum().item()\n",
        "\n",
        "            # Mid-epoch validation\n",
        "            if iteration % val_frequency == 0:\n",
        "                model.eval()\n",
        "                val_loss = 0.0\n",
        "                val_correct = 0\n",
        "                val_total = 0\n",
        "                with torch.no_grad():\n",
        "                    for val_inputs, val_labels in val_loader:\n",
        "                        val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
        "                        val_outputs = model(val_inputs)\n",
        "                        v_loss = criterion(val_outputs, val_labels)\n",
        "                        val_loss += v_loss.item() * val_inputs.size(0)\n",
        "                        _, val_predicted = torch.max(val_outputs.data, 1)\n",
        "                        val_total += val_labels.size(0)\n",
        "                        val_correct += (val_predicted == val_labels).sum().item()\n",
        "                current_val_loss = val_loss / val_total\n",
        "                print(f\"[Epoch {epoch+1}, Iteration {iteration}] Validation Loss: {current_val_loss:.4f}\")\n",
        "                early_stopping(current_val_loss, model)\n",
        "                if early_stopping.early_stop:\n",
        "                    print(\"Early stopping triggered during epoch validation\")\n",
        "                    break\n",
        "                model.train()  # switch back to training mode\n",
        "        else:\n",
        "            # Only executed if the inner loop did NOT break due to early stopping\n",
        "            pass\n",
        "\n",
        "        # Compute epoch statistics\n",
        "        epoch_loss = running_loss / total\n",
        "        epoch_acc = correct / total\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}/{n_epochs}, \"\n",
        "            f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Save checkpoint for this epoch\n",
        "        torch.save(\n",
        "            model.state_dict(),\n",
        "            os.path.join(checkpoint_path, f\"model_checkpoint_{epoch+1:02d}.pt\"),\n",
        "        )\n",
        "\n",
        "        # Step the learning rate scheduler\n",
        "        scheduler.step()\n",
        "        print(f\"Learning rate after epoch {epoch+1}: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "        # If early stopping was triggered, break out of epoch loop\n",
        "        if early_stopping.early_stop:\n",
        "            break\n",
        "\n",
        "    # Load the best model\n",
        "    model.load_state_dict(\n",
        "        torch.load(os.path.join(checkpoint_path, \"model_checkpoint_best.pt\"))\n",
        "    )\n",
        "\n",
        "    return (\n",
        "        model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        val_labels,\n",
        "        dict(Counter(val_labels)),\n",
        "        val_loader,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "LFRlz6rpCLuj"
      },
      "outputs": [],
      "source": [
        "# Fine-tuning hyperparameters (matching MATLAB NN_prep_for_classify.m)\n",
        "FINE_TUNE_MAX_EPOCHS = 1\n",
        "FINE_TUNE_MINIBATCH_SIZE = 32\n",
        "FINE_TUNE_INITIAL_LEARNING_RATE = 1e-6\n",
        "\n",
        "\n",
        "def nn_prep_for_classify(model, val_loader, train_loader):\n",
        "    \"\"\"Fine-tune the given model for one epoch with a low learning rate using the training and validation datasets.\n",
        "\n",
        "    Parameters:\n",
        "        model: PyTorch model.\n",
        "        val_loader: Validation DataLoader.\n",
        "        train_loader: Training DataLoader.\n",
        "\n",
        "    Returns:\n",
        "        model: The fine-tuned PyTorch model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Setup optimizer for fine-tuning with very low learning rate\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=FINE_TUNE_INITIAL_LEARNING_RATE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Determine validation frequency: floor(number of training iterations per epoch)\n",
        "    val_frequency = max(1, len(train_loader.dataset) // FINE_TUNE_MINIBATCH_SIZE)\n",
        "\n",
        "    model.train()\n",
        "    iteration = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, target_labels in train_loader:\n",
        "        iteration += 1\n",
        "        inputs, target_labels = inputs.to(device), target_labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, target_labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        # Mid-epoch validation\n",
        "        if iteration % val_frequency == 0:\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "            with torch.no_grad():\n",
        "                for val_inputs, val_labels in val_loader:\n",
        "                    val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
        "                    val_outputs = model(val_inputs)\n",
        "                    v_loss = criterion(val_outputs, val_labels)\n",
        "                    val_loss += v_loss.item() * val_inputs.size(0)\n",
        "                    _, val_predicted = torch.max(val_outputs.data, 1)\n",
        "                    val_total += val_labels.size(0)\n",
        "                    val_correct += (val_predicted == val_labels).sum().item()\n",
        "            current_val_loss = val_loss / val_total\n",
        "            current_val_acc = val_correct / val_total\n",
        "            print(f\"[Iteration {iteration}] Fine-tuning - Mid-epoch Val Loss: {current_val_loss:.4f}, Val Acc: {current_val_acc:.4f}\")\n",
        "            model.train()  # Switch back to training mode\n",
        "\n",
        "    # End of epoch: Evaluate on validation set\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, target_labels in val_loader:\n",
        "            inputs, target_labels = inputs.to(device), target_labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, target_labels)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += target_labels.size(0)\n",
        "            val_correct += (predicted == target_labels).sum().item()\n",
        "    val_epoch_loss = val_loss / val_total\n",
        "    val_epoch_acc = val_correct / val_total\n",
        "\n",
        "    print(f'Fine-tuning - Final Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "8YjMHj0CNjGF"
      },
      "outputs": [],
      "source": [
        "def precision(M):\n",
        "    \"\"\"Calculate the precision vector from a confusion matrix M.\n",
        "    Precision is defined as diag(M) / sum(M, axis=1).\n",
        "    Parameters:\n",
        "        M (np.ndarray): Confusion matrix.\n",
        "    Returns:\n",
        "        np.ndarray: The per-class precision.\n",
        "    \"\"\"\n",
        "    M = np.array(M, dtype=float)\n",
        "    # Avoid division by zero by adding eps\n",
        "    eps = np.finfo(float).eps\n",
        "    p = np.diag(M) / (np.sum(M, axis=1) + eps)\n",
        "    return p\n",
        "\n",
        "\n",
        "def recall(M):\n",
        "    \"\"\"Calculate the recall vector from a confusion matrix M.\n",
        "    Recall is defined as diag(M) / sum(M, axis=0).\n",
        "    Parameters:\n",
        "        M (np.ndarray): Confusion matrix.\n",
        "    Returns:\n",
        "        np.ndarray: The per-class recall.\n",
        "    \"\"\"\n",
        "    M = np.array(M, dtype=float)\n",
        "    eps = np.finfo(float).eps\n",
        "    r = np.diag(M) / (np.sum(M, axis=0) + eps)\n",
        "    return r\n",
        "\n",
        "\n",
        "def f1_score(p, r):\n",
        "    \"\"\"Calculate the F1 score given precision and recall vectors.\n",
        "    The F1 score is defined as 2*(p*r)/(p+r). If (p+r)==0, F1 is set to 0.\n",
        "    Parameters:\n",
        "        p (np.ndarray): Precision vector.\n",
        "        r (np.ndarray): Recall vector.\n",
        "    Returns:\n",
        "        np.ndarray: The per-class F1 score.\n",
        "    \"\"\"\n",
        "    eps = np.finfo(float).eps\n",
        "    f = np.where((p + r) > 0, 2 * p * r / (p + r + eps), 0)\n",
        "    return f\n",
        "\n",
        "\n",
        "def f1_metrics(M, label_counts):\n",
        "    \"\"\"Compute per-class precision, recall, F1 score and weighted metrics.\n",
        "\n",
        "    Parameters:\n",
        "        M (np.ndarray): Confusion matrix.\n",
        "        label_counts (array-like): Counts for each label (should sum to the total).\n",
        "\n",
        "    Returns:\n",
        "        tuple: (precision_vector, recall_vector, f1_vector, weighted_precision, weighted_recall, weighted_f1)\n",
        "    \"\"\"\n",
        "    label_counts = np.array(label_counts, dtype=float)\n",
        "    weights = label_counts / (np.sum(label_counts) + np.finfo(float).eps)\n",
        "    p = precision(M)\n",
        "    r = recall(M)\n",
        "    f = f1_score(p, r)\n",
        "    weighted_p = np.sum(p * weights)\n",
        "    weighted_r = np.sum(r * weights)\n",
        "    weighted_f = np.sum(f * weights)\n",
        "    return p, r, f, weighted_p, weighted_r, weighted_f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "Xpe4zj5rBs1S"
      },
      "outputs": [],
      "source": [
        "# Helper function to classify a dataset using the PyTorch model\n",
        "def classify_dataset(model, dataloader):\n",
        "    \"\"\"Return predicted labels for the dataset.\"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            if device.type == 'cuda':\n",
        "                with torch.cuda.amp.autocast(device_type='cuda'):\n",
        "                    outputs = model(inputs)\n",
        "            else:\n",
        "                outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    return np.array(all_preds)\n",
        "\n",
        "\n",
        "# Helper function to compute overall accuracy\n",
        "def compute_accuracy(pred_labels, true_labels):\n",
        "    import torch\n",
        "    if torch.is_tensor(true_labels):\n",
        "        true_labels = true_labels.cpu().numpy().astype(int)\n",
        "    else:\n",
        "        true_labels = np.array(true_labels, dtype=int)\n",
        "    return np.sum(pred_labels == true_labels) / len(true_labels)\n",
        "\n",
        "\n",
        "# Added helper function to run training, fine-tuning and evaluation for given label type\n",
        "def run_evaluation(files, numeric_labels, equalize, minibatch_size, validation_patience, checkpoint_path, skip_training=False):\n",
        "    model, train_loader, val_loader, lbls, lbl_counts, _ = nn_function(\n",
        "        files, numeric_labels, equalize_labels=equalize, minibatch_size=minibatch_size,\n",
        "        validation_patience=validation_patience, checkpoint_path=checkpoint_path, use_amp=(device.type=='cuda'), skip_training=skip_training\n",
        "    )\n",
        "\n",
        "    # Fine-tune for classification\n",
        "    model = nn_prep_for_classify(model, val_loader, train_loader)\n",
        "\n",
        "    # Get predictions\n",
        "    preds = classify_dataset(model, val_loader)\n",
        "\n",
        "    # Compute overall accuracy using true labels extracted from the validation dataset\n",
        "    true_labels = np.array(val_loader.dataset.labels, dtype=int)\n",
        "    acc = compute_accuracy(preds, true_labels)\n",
        "\n",
        "    # Compute confusion matrix and metrics\n",
        "    conf = confusion_matrix(true_labels, preds)\n",
        "    p, r, f1, wp, wr, wf1 = f1_metrics(conf, list(lbl_counts.values()))\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': acc,\n",
        "        'weighted_precision': wp,\n",
        "        'weighted_recall': wr,\n",
        "        'weighted_f1': wf1,\n",
        "        'preds': preds,\n",
        "        'labels': true_labels,\n",
        "        'confusion': conf\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def train(label_type='valence'):\n",
        "    # Read data from Excel, adjust file name and columns as needed\n",
        "    # Assuming the Excel file is named 'SoundwelDatasetKey.xlsx' and is in the current directory\n",
        "    excel_file = \"/content/drive/MyDrive/Colab Notebooks/soundwel_sound_analysis/soundwel/SoundwelDatasetKey.xlsx\"\n",
        "    data = pd.read_excel(excel_file)\n",
        "\n",
        "    # Extract columns (adjust column names/indexes based on actual data)\n",
        "    # For this example, we assume the Excel has columns: 'File', 'Valence', 'Context', 'Site'\n",
        "    Files = data['Spectrogram Filename'].tolist()\n",
        "\n",
        "    # Append directory to Files\n",
        "    Files = [os.path.join('/content/drive/MyDrive/Colab Notebooks/soundwel_sound_analysis/soundwel/Soundwel Dataset - Audio and Spectrograms', f) for f in Files]\n",
        "\n",
        "    Valence = data['Valence'].tolist()\n",
        "    Context = data['Context'].tolist()  # Uncommented to handle context classification\n",
        "    Site = data['Recording Team'].tolist()\n",
        "\n",
        "    # Convert labels to numeric categories\n",
        "    # Create mappings for valence and context\n",
        "    valence_categories = {cat: idx for idx, cat in enumerate(sorted(set(Valence)))}\n",
        "    context_categories = {cat: idx for idx, cat in enumerate(sorted(set(Context)))}  # Added for context\n",
        "    site_labels = sorted(set(Site))\n",
        "\n",
        "    Valence_numeric = [valence_categories[x] for x in Valence]\n",
        "    Context_numeric = [context_categories[x] for x in Context]  # Added for context\n",
        "\n",
        "    # Define checkpoint directory bases\n",
        "    checkpoint_base_val = os.path.join('checkpoints', 'Valence')\n",
        "    checkpoint_base_con = os.path.join('checkpoints', 'Context')\n",
        "    os.makedirs(checkpoint_base_val, exist_ok=True)\n",
        "    os.makedirs(checkpoint_base_con, exist_ok=True)\n",
        "\n",
        "    # Dictionaries to store metrics\n",
        "    overall_metrics_val = {}\n",
        "    overall_metrics_con = {}  # Added for context\n",
        "    site_accuracy_val = defaultdict(dict)\n",
        "    site_accuracy_con = defaultdict(dict)  # Added for context\n",
        "\n",
        "    # Loop over 12 iterations (mimicking MATLAB for i = 1:12)\n",
        "    for i in range(1, 2):\n",
        "        print(f\"Beginning Loop: {i}\")\n",
        "\n",
        "        # Define checkpoint directory for this iteration\n",
        "        cp_val = os.path.join(checkpoint_base_val, f'Iter{i}')\n",
        "        cp_con = os.path.join(checkpoint_base_con, f'Iter{i}')\n",
        "        os.makedirs(cp_val, exist_ok=True)\n",
        "        os.makedirs(cp_con, exist_ok=True)\n",
        "\n",
        "        if label_type in ['both', 'valence']:\n",
        "            # Run evaluation for valence\n",
        "            val_metrics_dict = run_evaluation(Files, Valence_numeric, True, 32, 5, cp_val, skip_training=False)\n",
        "            print(f\"Iteration {i} - Valence Accuracy: {val_metrics_dict['accuracy']:.2f}\")\n",
        "            overall_metrics_val[i] = val_metrics_dict\n",
        "            for site in site_labels:\n",
        "                site_accuracy_val[site][i] = val_metrics_dict['accuracy']\n",
        "        if label_type in ['both', 'context']:\n",
        "            # Run evaluation for context\n",
        "            con_metrics_dict = run_evaluation(Files, Context_numeric, False, 32, 5, cp_con, skip_training=False)\n",
        "            print(f\"Iteration {i} - Context Accuracy: {con_metrics_dict['accuracy']:.2f}\")\n",
        "            overall_metrics_con[i] = con_metrics_dict\n",
        "            for site in site_labels:\n",
        "                site_accuracy_con[site][i] = con_metrics_dict['accuracy']\n",
        "\n",
        "    # Save metrics to file or print summary\n",
        "    print(\"Overall Valence Metrics:\", overall_metrics_val)\n",
        "    print(\"Overall Context Metrics:\", overall_metrics_con)\n",
        "    print(\"Site-wise Valence Accuracies:\", dict(site_accuracy_val))\n",
        "    print(\"Site-wise Context Accuracies:\", dict(site_accuracy_con))\n",
        "\n",
        "    # New block to run site_validation_imds from the nn_function overall\n",
        "    # try:\n",
        "    #     from site_validation_imds import site_validation_imds\n",
        "    #     # Define the directory containing the soundwel images\n",
        "    #     image_dir = 'soundwel'\n",
        "    #     # List image files in the directory with extensions png, jpg, jpeg\n",
        "    #     image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    #     # Create dummy labels (e.g., all zeros)\n",
        "    #     dummy_labels = [0] * len(image_files)\n",
        "\n",
        "    #     print('Running site_validation_imds on image files:', image_files)\n",
        "    #     dataset_site = site_validation_imds(image_files, dummy_labels, base_dir=image_dir)\n",
        "    #     # Get the first batch to check\n",
        "    #     images, labels = next(iter(dataset_site))\n",
        "    #     print('Site validation batch images shape:', images.shape, 'labels:', labels)\n",
        "    # except Exception as e:\n",
        "    #     print('Error during site validation:', e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05avP9XUSgAJ",
        "outputId": "391f53ce-d7d2-4a21-98dc-3b7910765ba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning Loop: 1\n",
            "[Epoch 1, Iteration 101] Validation Loss: 0.5243\n",
            "Validation loss decreased (inf --> 0.524257). Saving model...\n",
            "Epoch 1/20, Train Loss: 0.5729, Train Acc: 0.7032\n",
            "Learning rate after epoch 1: 0.001000\n",
            "[Epoch 2, Iteration 101] Validation Loss: 0.4912\n",
            "Validation loss decreased (0.524257 --> 0.491238). Saving model...\n",
            "Epoch 2/20, Train Loss: 0.5020, Train Acc: 0.7689\n",
            "Learning rate after epoch 2: 0.001000\n"
          ]
        }
      ],
      "source": [
        "train(label_type='valence')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
